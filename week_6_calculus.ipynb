{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. One-sided finite differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv(f, x, h):\n",
    "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
    "    \n",
    "    Compute the derivative using the one-sided rule of the approximation order of $O(h^2)$.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function to differentiate\n",
    "    x : float\n",
    "        The point to compute the derivative at.\n",
    "    h : float\n",
    "        The step size for the finite different rule.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fder : derivative of f(x) at point x using the step size h.\n",
    "    \"\"\"\n",
    "    \n",
    "    Y = f(x+h)\n",
    "    y = f(x)\n",
    "    \n",
    "    d = (Y-y)/(h)\n",
    "    \n",
    "    return (d)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test I.1\n",
    "\n",
    "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
    "\n",
    " (10% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.00010000000000000002\n",
      "0.001 1e-06\n",
      "0.0001 1.0000000000000002e-08\n",
      "1e-05 1.0000000000000002e-10\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(lambda x: x**3, x, h)\n",
    "    print(h, err)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Мы ожидали, что производная нашей функции в 0 будет равна 0, а также, что погрешность будет тем меньше, чем меньше h, причём, пропорционально h^2. Собственно это мы и получили.\n",
    " \n",
    " На всякий случай я проверила для x=1 и x=2. Для этих значений я получила такой же результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.2\n",
    "\n",
    "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
    "(15% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der2(f, x, h):\n",
    "    \n",
    "    Y = f(x+h)\n",
    "    y = f(x-h)\n",
    "    \n",
    "    d = (Y-y)/(2*h)\n",
    "    \n",
    "    return (d)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def f(x):\n",
    "    return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    return x * (2.*log(x) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01   1.015033250331677   1.0000333336666771   1.0\n",
      "0.001   1.0015003332499228   1.0000003333333118   1.0\n",
      "0.0001   1.0001500033331399   1.0000000033332233   1.0\n",
      "1e-05   1.0000150000398844   1.0000000000343334   1.0\n",
      "1e-06   1.0000014999180666   0.9999999999735779   1.0\n",
      "1e-06   1.0000014999180666   0.9999999999735779   1.0\n",
      "1e-07   1.0000001505838707   1.0000000000287592   1.0\n",
      "1e-08   1.0000000089225287   0.9999999994736439   1.0\n",
      "1e-09   1.0000000842403711   1.00000002722922   1.0\n",
      "1e-10   1.000000082890371   1.000000082740371   1.0\n",
      "1e-11   1.000000082755371   1.000000082740371   1.0\n",
      "1e-12   1.0000889005838414   1.00003338943111   1.0\n",
      "1e-13   0.9992007221627905   0.9997558336749531   1.0\n",
      "1e-14   0.9992007221626559   0.9992007221626409   1.0\n",
      "1e-15   1.1102230246251583   1.054711873393899   1.0\n",
      "1e-16   0.0   0.5551115123125782   1.0\n"
     ]
    }
   ],
   "source": [
    "x = 1\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15, 1e-16]:\n",
    "    err = deriv(f, x, h)\n",
    "    err2 = der2(f, x, h)\n",
    "    fd = fder(x)\n",
    "    print(h,\" \", err,\" \", err2,\" \", fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замечаем, что для первого метода рост начинается с 10^(-9), а для второго с 10^(-8). При этом второй метод точнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test I.3 \n",
    "\n",
    "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
    "(25% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def der3(f, x, h):\n",
    "    \n",
    "    Y = f(x+2*h)\n",
    "    y = f(x+h)\n",
    "    z = f(x)\n",
    "    \n",
    "    d = (-3*x/2 + 2*y - Y/2)/h\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 -0.04605170185988091\n",
      "0.001 -0.006907755278982136\n",
      "0.0001 -0.0009210340371976182\n",
      "1e-05 -0.0001151292546497023\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x**2 * log(x)\n",
    "    \n",
    "def fder(x):\n",
    "    if x == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x*(2*log(x) + 1)\n",
    "\n",
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(f, x, h) - fder(x)\n",
    "    print(h, err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это вообще законно, что мы так быстро скатываемся в возрастание ошибки???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Midpoint rule "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midpoint_rule(func, a, b, eps):\n",
    "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function to integrate.\n",
    "    a : float\n",
    "        The lower limit of integration.\n",
    "    b : float\n",
    "        The upper limit of integration.\n",
    "    eps : float\n",
    "        The target accuracy of the estimate.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    integral : float\n",
    "        The estimate of $\\int_a^b f(x) dx$.\n",
    "    \"\"\"\n",
    "    # ... ENTER YOUR CODE HERE ...\n",
    "    \n",
    "    # делим на отрезки\n",
    "    \n",
    "    f = func\n",
    "    N = 1\n",
    "    I = 0\n",
    "    I2 = 0\n",
    "    I0 = 1000000000\n",
    "    delta = 100000000\n",
    "    \n",
    "    while delta>= eps:\n",
    "        for i in range (N):\n",
    "            l = (b-a)/N\n",
    "            \n",
    "            miniI = l*f(a + l/2 + i*l)\n",
    "            I = I+miniI  \n",
    "        N = N*2\n",
    "        delta = abs(I0-I)\n",
    "        I0 = I\n",
    "        \n",
    "    for i in range (2*N):\n",
    "            l = (b-a)/(2*N)\n",
    "            miniI2 = l*f(a + l/2 + i*l)\n",
    "            I2 = I2+miniI2\n",
    "            \n",
    "    return I, I2, N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.1\n",
    "\n",
    "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
    "\n",
    "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
    "\n",
    "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
    "(20% of the total grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x+1\n",
    "I, I2, N = midpoint_rule(f, 0, 1, 10**(-4))\n",
    "print (I, I2, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test II.2\n",
    "\n",
    "Now use your midpoint rule to compute the value of\n",
    "\n",
    "$$\n",
    "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
    "$$\n",
    "\n",
    "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
    "\n",
    "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
    "\n",
    "(30% of the total grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin\n",
    "\n",
    "def s(x):\n",
    "    s = sin(x**0.5)/x\n",
    "    return s\n",
    "\n",
    "I, I2, N = midpoint_rule(s, 0, 1, 10**(-4))\n",
    "print(I, I2, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Вот где-то тут ошибка, но я никак не могу найти где. Почему-то оно очень странно считает. Не прогоняя все N. Он очень долго считает, я не понимаю, в чём дело. Я умываю руки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
